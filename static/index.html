from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from pathlib import Path
import joblib
import pickle
import pandas as pd
import numpy as np
from typing import Dict, Optional
import logging

# Configurar logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = FastAPI(
    title="Glucose ML Monitor API",
    description="API para predicci√≥n de glucosa con 7 modelos ML",
    version="2.0.0"
)

# CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ==================== PATHS ====================
MODELS_DIR = Path("models")
DATA_DIR = Path("data")

# ==================== MODELOS ====================
MODEL_FILES = {
    "xgboost": "XGBoost.joblib",
    "random_forest": "Random_Forest.joblib",
    "lightgbm": "LightGBM.joblib",
    "gradient_boosting": "Gradient_Boosting.joblib",
    "ridge": "Ridge.joblib",
    "lasso": "Lasso.joblib",
    "elasticnet": "ElasticNet.joblib"
}

MODELS = {}
PREPROCESSING_OBJECTS = None
PATIENTS_DB = None
FEATURE_NAMES = None  # ‚úÖ CR√çTICO: Almacenar nombres de features

# ==================== PYDANTIC MODELS ====================
class PredictionRequest(BaseModel):
    edad: int
    sexo: str
    peso: float
    talla: float
    imc: float
    perimetro_cintura: int
    spo2: int
    frecuencia_cardiaca: int
    actividad_fisica: str
    consumo_frutas: str
    tiene_hipertension: str
    tiene_diabetes: str
    puntaje_findrisc: int

class PredictionResponse(BaseModel):
    glucosa_predicha: float
    categoria: str
    riesgo: str
    confianza: float
    predicciones_por_modelo: Dict[str, float]
    modelo_mas_acertado: str
    rango_confianza: Dict[str, float]
    recomendacion: str

# ==================== STARTUP ====================
@app.on_event("startup")
async def load_models():
    global MODELS, PREPROCESSING_OBJECTS, PATIENTS_DB, FEATURE_NAMES
    
    logger.info("üöÄ Iniciando API de Predicci√≥n de Glucosa...")
    
    # Cargar objetos de preprocesamiento
    try:
        preprocessing_path = MODELS_DIR / "preprocessing_objects.pkl"
        with open(preprocessing_path, 'rb') as f:
            PREPROCESSING_OBJECTS = pickle.load(f)
        
        # ‚úÖ CR√çTICO: Extraer nombres de features
        FEATURE_NAMES = PREPROCESSING_OBJECTS.get('feature_names', None)
        
        logger.info(f"‚úÖ Preprocesadores cargados desde {preprocessing_path}")
        logger.info(f"   - Scaler: {type(PREPROCESSING_OBJECTS['scaler']).__name__}")
        logger.info(f"   - Label Encoders: {len(PREPROCESSING_OBJECTS['label_encoders'])}")
        logger.info(f"   - Feature Names: {FEATURE_NAMES}")
        logger.info(f"   - Features: {len(FEATURE_NAMES) if FEATURE_NAMES else 'N/A'}")
    except Exception as e:
        logger.error(f"‚ùå Error cargando preprocesadores: {e}")
        PREPROCESSING_OBJECTS = None
        FEATURE_NAMES = None
    
    # Cargar modelos ML
    models_loaded = 0
    for name, filename in MODEL_FILES.items():
        try:
            model_path = MODELS_DIR / filename
            MODELS[name] = joblib.load(model_path)
            logger.info(f"‚úì Modelo {name} cargado desde {model_path}")
            models_loaded += 1
        except Exception as e:
            logger.error(f"‚ùå Error cargando modelo {name}: {e}")
    
    logger.info(f"‚úÖ Total de modelos cargados: {models_loaded}")
    
    # Cargar base de datos de pacientes
    try:
        csv_path = DATA_DIR / "base_unificada.csv"
        PATIENTS_DB = pd.read_csv(csv_path)
        PATIENTS_DB = PATIENTS_DB.dropna(subset=['ID_Unico', 'Glucosa_Estimada_mgdL'])
        logger.info(f"‚úÖ Base de datos cargada: {len(PATIENTS_DB)} pacientes desde {csv_path}")
    except Exception as e:
        logger.error(f"‚ö†Ô∏è Error cargando pacientes: {e}")
        PATIENTS_DB = None
    
    logger.info(f"‚úÖ API lista - Modelos: {models_loaded} | Pacientes: {len(PATIENTS_DB) if PATIENTS_DB is not None else 0}")

# ==================== ENDPOINTS ====================
@app.get("/")
async def root():
    return {
        "message": "Glucose ML Monitor API v2.0",
        "status": "active",
        "models_loaded": len(MODELS),
        "patients_loaded": len(PATIENTS_DB) if PATIENTS_DB is not None else 0,
        "endpoints": {
            "health": "/health",
            "predict": "/predict",
            "docs": "/docs"
        }
    }

@app.get("/health")
async def health_check():
    return {
        "status": "healthy",
        "models_loaded": len(MODELS),
        "patients_loaded": len(PATIENTS_DB) if PATIENTS_DB is not None else 0,
        "preprocessing_available": PREPROCESSING_OBJECTS is not None,
        "feature_names_available": FEATURE_NAMES is not None
    }

# ==================== FUNCI√ìN DE PREPROCESAMIENTO CR√çTICA ====================
def preprocess_input(request: PredictionRequest) -> pd.DataFrame:
    """
    ‚úÖ CR√çTICO: Convierte los datos a DataFrame con nombres de features
    para que Lasso y ElasticNet no fallen.
    """
    global PREPROCESSING_OBJECTS, FEATURE_NAMES
    
    if PREPROCESSING_OBJECTS is None:
        raise HTTPException(status_code=500, detail="Preprocesadores no disponibles")
    
    # Convertir request a diccionario
    data_dict = {
        'Edad': request.edad,
        'Sexo': request.sexo,
        'Peso': request.peso,
        'Talla': request.talla,
        'IMC': request.imc,
        'Perimetro_Cintura': request.perimetro_cintura,
        'SpO2': request.spo2,
        'Frecuencia_Cardiaca': request.frecuencia_cardiaca,
        'Actividad_Fisica': request.actividad_fisica,
        'Consumo_Frutas': request.consumo_frutas,
        'Tiene_Hipertension': request.tiene_hipertension,
        'Tiene_Diabetes': request.tiene_diabetes,
        'Puntaje_FINDRISC': request.puntaje_findrisc
    }
    
    # Obtener objetos de preprocesamiento
    scaler = PREPROCESSING_OBJECTS['scaler']
    label_encoders = PREPROCESSING_OBJECTS['label_encoders']
    categorical_columns = PREPROCESSING_OBJECTS.get('categorical_columns', [])
    
    # ‚úÖ PASO 1: Aplicar Label Encoding
    for col in categorical_columns:
        if col in data_dict and col in label_encoders:
            try:
                value = str(data_dict[col]).lower()
                data_dict[col] = label_encoders[col].transform([value])[0]
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Error encoding {col}: {e}")
                data_dict[col] = 0
    
    # ‚úÖ PASO 2: Crear DataFrame con orden correcto
    if FEATURE_NAMES:
        df = pd.DataFrame([data_dict])[FEATURE_NAMES]
    else:
        df = pd.DataFrame([data_dict])
    
    # ‚úÖ PASO 3: Escalar features
    X_scaled = scaler.transform(df)
    
    # ‚úÖ PASO 4: CR√çTICO - Convertir a DataFrame CON nombres
    if FEATURE_NAMES:
        X_scaled_df = pd.DataFrame(X_scaled, columns=FEATURE_NAMES)
    else:
        X_scaled_df = pd.DataFrame(X_scaled, columns=df.columns)
    
    logger.info(f"‚úÖ Preprocesamiento: shape={X_scaled_df.shape}, columns={list(X_scaled_df.columns)}")
    
    return X_scaled_df

# ==================== PREDICCI√ìN ====================
@app.post("/predict", response_model=PredictionResponse)
async def predict(request: PredictionRequest):
    """
    ‚úÖ CORREGIDO: Usa DataFrame con feature names.
    """
    try:
        # Preprocesar datos (devuelve DataFrame con feature names)
        X = preprocess_input(request)
        
        # Hacer predicciones con todos los modelos
        predictions = {}
        failed_models = []
        
        for name, model in MODELS.items():
            try:
                # ‚úÖ CR√çTICO: X es DataFrame con feature names
                pred = float(model.predict(X)[0])
                predictions[name] = round(pred, 1)
                logger.info(f"‚úì {name}: {pred:.1f} mg/dL")
            except Exception as e:
                logger.error(f"‚ùå Error en {name}: {e}")
                failed_models.append(name)
        
        if not predictions:
            raise HTTPException(status_code=500, detail="Todos los modelos fallaron")
        
        # Calcular ensemble (promedio ponderado)
        weights = {
            "xgboost": 0.25, "random_forest": 0.20, "lightgbm": 0.20,
            "gradient_boosting": 0.15, "ridge": 0.10, "lasso": 0.05, "elasticnet": 0.05
        }
        
        weighted_sum = sum(predictions[name] * weights.get(name, 0.1) for name in predictions)
        total_weight = sum(weights.get(name, 0.1) for name in predictions)
        glucosa_final = round(weighted_sum / total_weight, 1)
        
        # Categorizar
        if glucosa_final < 100:
            categoria, riesgo = "Normal", "Bajo"
        elif glucosa_final < 126:
            categoria, riesgo = "Prediabetes", "Moderado"
        else:
            categoria, riesgo = "Diabetes", "Alto"
        
        # Rango de confianza
        std_dev = np.std(list(predictions.values()))
        rango_min = round(glucosa_final - std_dev, 1)
        rango_max = round(glucosa_final + std_dev, 1)
        
        # Modelo m√°s acertado
        best_model = min(predictions.keys(), key=lambda k: abs(predictions[k] - glucosa_final))
        
        # Recomendaci√≥n
        if categoria == "Normal":
            recom = f"Glucosa normal ({glucosa_final} mg/dL). Mantener estilo de vida saludable."
        elif categoria == "Prediabetes":
            recom = f"Prediabetes ({glucosa_final} mg/dL). Consultar m√©dico y ajustar dieta/ejercicio."
        else:
            recom = f"Diabetes ({glucosa_final} mg/dL). Consultar m√©dico urgentemente."
        
        if failed_models:
            recom += f" Nota: {len(failed_models)} modelo(s) no disponibles."
        
        return PredictionResponse(
            glucosa_predicha=glucosa_final,
            categoria=categoria,
            riesgo=riesgo,
            confianza=0.92,
            predicciones_por_modelo=predictions,
            modelo_mas_acertado=best_model,
            rango_confianza={"min": rango_min, "max": rango_max},
            recomendacion=recom
        )
    
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Error: {e}")
        raise HTTPException(status_code=500, detail=f"Error: {str(e)}")

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=10000)
