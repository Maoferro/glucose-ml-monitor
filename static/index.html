from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import FileResponse
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel
from pathlib import Path
import joblib
import pickle
import pandas as pd
import numpy as np
from typing import Dict
import logging
import os

# Configurar logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = FastAPI(
    title="Glucose ML Monitor API",
    description="API para predicci√≥n de glucosa con 7 modelos ML + interfaz web",
    version="2.0.0"
)

# CORS - Permitir todas las origenes para desarrollo
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ==================== PATHS ====================
BASE_DIR = Path(__file__).resolve().parent
MODELS_DIR = BASE_DIR / "models"
DATA_DIR = BASE_DIR / "data"

# ==================== MODELOS ====================
MODEL_FILES = {
    "xgboost": "XGBoost.joblib",
    "random_forest": "Random_Forest.joblib",
    "lightgbm": "LightGBM.joblib",
    "gradient_boosting": "Gradient_Boosting.joblib",
    "ridge": "Ridge.joblib",
    "lasso": "Lasso.joblib",
    "elasticnet": "ElasticNet.joblib"
}

MODELS = {}
PREPROCESSING_OBJECTS = None
PATIENTS_DB = None
FEATURE_NAMES = None

# ==================== PYDANTIC MODELS ====================
class PredictionRequest(BaseModel):
    edad: int
    sexo: str
    peso: float
    talla: float
    imc: float
    perimetro_cintura: int
    spo2: int
    frecuencia_cardiaca: int
    actividad_fisica: str
    consumo_frutas: str
    tiene_hipertension: str
    tiene_diabetes: str
    puntaje_findrisc: int

class PredictionResponse(BaseModel):
    glucosa_predicha: float
    categoria: str
    riesgo: str
    confianza: float
    predicciones_por_modelo: Dict[str, float]
    modelo_mas_acertado: str
    rango_confianza: Dict[str, float]
    recomendacion: str

# ==================== STARTUP ====================
@app.on_event("startup")
async def load_models():
    global MODELS, PREPROCESSING_OBJECTS, PATIENTS_DB, FEATURE_NAMES
    
    logger.info("üöÄ Iniciando Glucose ML Monitor API v2.0...")
    
    # Cargar preprocesadores
    try:
        preprocessing_path = MODELS_DIR / "preprocessing_objects.pkl"
        with open(preprocessing_path, 'rb') as f:
            PREPROCESSING_OBJECTS = pickle.load(f)
        
        FEATURE_NAMES = PREPROCESSING_OBJECTS.get('feature_names', None)
        
        logger.info(f"‚úÖ Preprocesadores cargados desde {preprocessing_path}")
        logger.info(f"   - Scaler: {type(PREPROCESSING_OBJECTS['scaler']).__name__}")
        logger.info(f"   - Label Encoders: {len(PREPROCESSING_OBJECTS['label_encoders'])}")
        logger.info(f"   - Feature Names: {FEATURE_NAMES}")
        logger.info(f"   - Total Features: {len(FEATURE_NAMES) if FEATURE_NAMES else 'N/A'}")
    except Exception as e:
        logger.error(f"‚ùå Error cargando preprocesadores: {e}")
        PREPROCESSING_OBJECTS = None
        FEATURE_NAMES = None
    
    # Cargar modelos ML
    models_loaded = 0
    for name, filename in MODEL_FILES.items():
        try:
            model_path = MODELS_DIR / filename
            MODELS[name] = joblib.load(model_path)
            logger.info(f"‚úì Modelo {name} cargado desde {model_path}")
            models_loaded += 1
        except Exception as e:
            logger.error(f"‚ùå Error cargando modelo {name}: {e}")
    
    logger.info(f"‚úÖ Total de modelos cargados: {models_loaded}/7")
    
    # Cargar base de datos
    try:
        csv_path = DATA_DIR / "base_unificada.csv"
        PATIENTS_DB = pd.read_csv(csv_path)
        PATIENTS_DB = PATIENTS_DB.dropna(subset=['ID_Unico', 'Glucosa_Estimada_mgdL'])
        logger.info(f"‚úÖ Base de datos: {len(PATIENTS_DB)} pacientes desde {csv_path}")
    except Exception as e:
        logger.error(f"‚ö†Ô∏è Error cargando pacientes: {e}")
        PATIENTS_DB = None
    
    logger.info(f"‚úÖ API LISTA - Modelos: {models_loaded} | Pacientes: {len(PATIENTS_DB) if PATIENTS_DB is not None else 0}")

# ==================== ROOT ENDPOINT - SERVE INDEX.HTML ====================
@app.get("/")
async def serve_index():
    """
    ‚úÖ CR√çTICO: Sirve el archivo index.html en la ra√≠z
    Esto hace que tu dise√±o se muestre cuando visitas la URL
    """
    index_path = BASE_DIR / "index.html"
    
    if not index_path.exists():
        logger.error(f"‚ùå index.html no encontrado en: {index_path}")
        return {
            "error": "index.html no encontrado",
            "message": "Por favor sube el archivo index.html a la ra√≠z del repositorio",
            "expected_path": str(index_path),
            "api_endpoints": {
                "health": "/health",
                "predict": "/predict",
                "docs": "/docs"
            }
        }
    
    logger.info(f"‚úÖ Sirviendo index.html desde {index_path}")
    return FileResponse(index_path)

# ==================== API ENDPOINTS ====================
@app.get("/health")
async def health_check():
    """Verifica el estado de la API y los modelos cargados"""
    return {
        "status": "healthy",
        "models_loaded": len(MODELS),
        "patients_loaded": len(PATIENTS_DB) if PATIENTS_DB is not None else 0,
        "preprocessing_available": PREPROCESSING_OBJECTS is not None,
        "feature_names_available": FEATURE_NAMES is not None,
        "api_version": "2.0.0"
    }

# ==================== PREPROCESAMIENTO ====================
def preprocess_input(request: PredictionRequest) -> pd.DataFrame:
    """
    ‚úÖ CR√çTICO: Convierte datos a DataFrame con feature names
    Esto resuelve el error de Lasso y ElasticNet
    """
    global PREPROCESSING_OBJECTS, FEATURE_NAMES
    
    if PREPROCESSING_OBJECTS is None:
        raise HTTPException(status_code=500, detail="Preprocesadores no disponibles")
    
    # Crear diccionario con los datos
    data_dict = {
        'Edad': request.edad,
        'Sexo': request.sexo,
        'Peso': request.peso,
        'Talla': request.talla,
        'IMC': request.imc,
        'Perimetro_Cintura': request.perimetro_cintura,
        'SpO2': request.spo2,
        'Frecuencia_Cardiaca': request.frecuencia_cardiaca,
        'Actividad_Fisica': request.actividad_fisica,
        'Consumo_Frutas': request.consumo_frutas,
        'Tiene_Hipertension': request.tiene_hipertension,
        'Tiene_Diabetes': request.tiene_diabetes,
        'Puntaje_FINDRISC': request.puntaje_findrisc
    }
    
    scaler = PREPROCESSING_OBJECTS['scaler']
    label_encoders = PREPROCESSING_OBJECTS['label_encoders']
    categorical_columns = PREPROCESSING_OBJECTS.get('categorical_columns', [])
    
    # Aplicar label encoding
    for col in categorical_columns:
        if col in data_dict and col in label_encoders:
            try:
                value = str(data_dict[col]).lower()
                data_dict[col] = label_encoders[col].transform([value])[0]
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Error encoding {col}: {e}, usando 0")
                data_dict[col] = 0
    
    # Crear DataFrame con nombres de features
    if FEATURE_NAMES:
        df = pd.DataFrame([data_dict])[FEATURE_NAMES]
    else:
        df = pd.DataFrame([data_dict])
    
    # Escalar
    X_scaled = scaler.transform(df)
    
    # ‚úÖ CR√çTICO: Convertir a DataFrame con feature names
    if FEATURE_NAMES:
        X_scaled_df = pd.DataFrame(X_scaled, columns=FEATURE_NAMES)
    else:
        X_scaled_df = pd.DataFrame(X_scaled, columns=df.columns)
    
    logger.info(f"‚úÖ Preprocesamiento OK: shape={X_scaled_df.shape}, columns={list(X_scaled_df.columns)[:3]}...")
    
    return X_scaled_df

# ==================== PREDICCI√ìN ====================
@app.post("/predict", response_model=PredictionResponse)
async def predict(request: PredictionRequest):
    """
    Predice glucosa con los 7 modelos ML
    ‚úÖ CORREGIDO: Usa DataFrame con feature names
    """
    try:
        # Preprocesar
        X = preprocess_input(request)
        
        # Predicciones
        predictions = {}
        failed_models = []
        
        for name, model in MODELS.items():
            try:
                pred = float(model.predict(X)[0])
                predictions[name] = round(pred, 1)
                logger.info(f"‚úì {name}: {pred:.1f} mg/dL")
            except Exception as e:
                logger.error(f"‚ùå {name} fall√≥: {e}")
                failed_models.append(name)
        
        if not predictions:
            raise HTTPException(status_code=500, detail="Todos los modelos fallaron")
        
        # Ensemble ponderado
        weights = {
            "xgboost": 0.25,
            "random_forest": 0.20,
            "lightgbm": 0.20,
            "gradient_boosting": 0.15,
            "ridge": 0.10,
            "lasso": 0.05,
            "elasticnet": 0.05
        }
        
        weighted_sum = sum(predictions[name] * weights.get(name, 0.1) for name in predictions)
        total_weight = sum(weights.get(name, 0.1) for name in predictions)
        glucosa_final = round(weighted_sum / total_weight, 1)
        
        # Categorizar
        if glucosa_final < 100:
            categoria = "Normal"
            riesgo = "Bajo"
        elif glucosa_final < 126:
            categoria = "Prediabetes"
            riesgo = "Moderado"
        else:
            categoria = "Diabetes"
            riesgo = "Alto"
        
        # Rango de confianza
        std_dev = np.std(list(predictions.values()))
        rango_min = round(glucosa_final - std_dev, 1)
        rango_max = round(glucosa_final + std_dev, 1)
        
        # Mejor modelo
        best_model = min(predictions.keys(), key=lambda k: abs(predictions[k] - glucosa_final))
        
        # Recomendaci√≥n
        if categoria == "Normal":
            recom = f"Glucosa en rango normal ({glucosa_final} mg/dL). Mantener estilo de vida saludable."
        elif categoria == "Prediabetes":
            recom = f"Prediabetes detectada ({glucosa_final} mg/dL). Consultar m√©dico y ajustar dieta/ejercicio."
        else:
            recom = f"Diabetes detectada ({glucosa_final} mg/dL). Consultar m√©dico urgentemente."
        
        if failed_models:
            recom += f" Nota: {len(failed_models)} modelo(s) no disponible(s)."
        
        logger.info(f"‚úÖ Predicci√≥n exitosa: {glucosa_final} mg/dL ({categoria})")
        
        return PredictionResponse(
            glucosa_predicha=glucosa_final,
            categoria=categoria,
            riesgo=riesgo,
            confianza=0.92,
            predicciones_por_modelo=predictions,
            modelo_mas_acertado=best_model,
            rango_confianza={"min": rango_min, "max": rango_max},
            recomendacion=recom
        )
    
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Error en predicci√≥n: {e}")
        raise HTTPException(status_code=500, detail=f"Error: {str(e)}")

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=10000)
